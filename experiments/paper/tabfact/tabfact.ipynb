{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b279b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import glob\n",
    "from thucy.configuration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0613a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Verified'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_verdict(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    match = re.search(rf\"<verdict>(.*?)</verdict>\", text, re.DOTALL)\n",
    "    text = match.group(1).strip()\n",
    "    return text\n",
    "\n",
    "read_verdict(\"gpt-4o-mini/TabFact_1-29789-1.html.csv_0-trace_649936bc924440b887e9e243ec5dec19.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b44da6d",
   "metadata": {},
   "source": [
    "# Measuring Accuracy Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6447d96d",
   "metadata": {},
   "source": [
    "## TabFact Small Test Split\n",
    "\n",
    "First, you can download all the Tab-Fact pairs from this [json](https://github.com/wenhuchen/Table-Fact-Checking/blob/master/tokenized_data/test_examples.json). Then, you can download the **small** split (i.e., 1998 indices) from this [json (small)](https://github.com/wenhuchen/Table-Fact-Checking/blob/master/data/small_test_id.json).\n",
    "\n",
    "In the current directory, we already provide both of them: namely, `test_examples.json` and `small_test_id.json`. Let's load them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6c62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_examples.json\", \"r\") as file:\n",
    "    test_examples = json.load(file)\n",
    "\n",
    "with open(\"small_test_id.json\", \"r\") as file:\n",
    "    test_ids = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8863020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2-1570274-4.html.csv',\n",
       " [['tony lema be in the top 5 for the master tournament , the us open , and the open championship',\n",
       "   'tournament that tony lema have participate in include the master tournament , the us open , the pga championship and the open championship',\n",
       "   'the only tournament that tony lema win in be the open championship',\n",
       "   'tony lema do not win in the us open',\n",
       "   'tony lema make it to the top 10 in the pga championship , but do not continue on',\n",
       "   'tony lema be in the top 5 for the pga championship , the us open , and the open championship',\n",
       "   'tournament that tony lema have not participate in include the master tournament , the us open , the pga championship and the open championship',\n",
       "   'tournament that tony lema won in be pga championship',\n",
       "   'tony lema do not win in the pga championship',\n",
       "   'tony lema make it to the top 10 in the us open , but do not continue on'],\n",
       "  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "  'tony lema'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_examples.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d63faf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1-24560733-1.html.csv'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5170ff41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids[0] in test_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251869a",
   "metadata": {},
   "source": [
    "Here, **1** means that the claim is **entailed**, and **0** means that the claim is **refuted**. You have probably noticed the awful grammar of the claims... this has been cleaned up by [Wang et al. (2024)](https://arxiv.org/pdf/2401.04398) which we will use in the future work (we do not use the cleaned up version in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a952479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------  Model: gpt-5-mini -----------\n",
      "Accuracy: 94.34% , Total Tests: 1998 , Wrong Answers: 113\n",
      "\n",
      "-----------  Model: gpt-4o-mini -----------\n",
      "Accuracy: 93.69% , Total Tests: 1998 , Wrong Answers: 126\n"
     ]
    }
   ],
   "source": [
    "models = ['gpt-5-mini', 'gpt-4o-mini']\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    total_tests = 0\n",
    "    correct_answers = 0\n",
    "    \n",
    "    for filename in glob.glob(f\"{model}/TabFact*\"):\n",
    "        match = re.search(r'TabFact_(.+)_(\\d+)-trace', filename)\n",
    "        \n",
    "        if not match:\n",
    "            raise(\"What!?!?\")\n",
    "            \n",
    "        test_file, test_i = match.groups()\n",
    "    \n",
    "        # if test not in the \"small-set\" skip!\n",
    "        if test_file not in test_ids:\n",
    "            continue\n",
    "        \n",
    "        test_i = int(test_i)\n",
    "\n",
    "        # This is the ground truth\n",
    "        answer_i = test_examples[test_file][1][test_i]\n",
    "\n",
    "        # This is Thucy's verdict\n",
    "        verdict_str = read_verdict(model + '/' + filename.split('/')[-1])\n",
    "        \n",
    "        # Thucy predicts \"ENTAILED\" when it is Verified or Partly Verified, else \"REFUTED\"\n",
    "        verdict = 1 if verdict_str in ('Verified', 'Partly Verified') else 0\n",
    "    \n",
    "        total_tests += 1\n",
    "\n",
    "        # Count correct answers\n",
    "        correct_answers += int(verdict == answer_i)\n",
    "    \n",
    "    \n",
    "    accuracy = correct_answers / total_tests\n",
    "    print()\n",
    "    print(f\"-----------  Model: {model} -----------\")\n",
    "    print(f\"Accuracy: {100*accuracy:.2f}% , Total Tests: {total_tests} , Wrong Answers: {total_tests - correct_answers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb7951",
   "metadata": {},
   "source": [
    "# Recreating the Results of the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d9fd9e",
   "metadata": {},
   "source": [
    "## Download TabFact CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b93889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052fe338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thucy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
