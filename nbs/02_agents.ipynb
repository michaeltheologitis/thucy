{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ae3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a237b0a",
   "metadata": {},
   "source": [
    "# Agents: Prompts, Schemas, and Orchestration\n",
    "\n",
    "> In this module, we define the prompts, input/output schemas, and overall behavior of the different agents in our multi-agent system. Each agent has a specific role and expertise, allowing them to collaborate effectively to achieve complex tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdcc0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3e736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def description(pydantic_model):\n",
    "    \"Print the field descriptions of a Pydantic model\"\n",
    "    for name, field in pydantic_model.model_fields.items():\n",
    "        print(f\"{name}: {field.description}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057a272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89243b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pydantic import Field, BaseModel\n",
    "from typing import Literal\n",
    "from thucy.toolbox import *\n",
    "from agents import Agent, Runner, function_tool\n",
    "from thucy.config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d765cc",
   "metadata": {},
   "source": [
    "## Expert Agent: Data Expert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9820f550",
   "metadata": {},
   "source": [
    "The Data performs a high-level survey of available data sources without diving into detailed schemas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a58317a",
   "metadata": {},
   "source": [
    "### Prompt Definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580425de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "DATA_EXPERT_PROMPT = \"\"\"\n",
    "# Role and Objective\n",
    "You are a data expert that explores available sources. Your task is to perform a rapid, one-time survey of all accessible data sources. Your goal is to identify what databases, data stores, or connected sources exist and summarize, at a high level, what type of data each likely contains.\n",
    "\n",
    "# Exploration Scope\n",
    "Focus on high-level data assets only — databases, schemas, APIs, or data files. Do not inspect or describe tables, columns, or detailed schemas. You are creating a top-down map of the data environment, not a deep schema inventory.\n",
    "\n",
    "# Grounding and Accuracy\n",
    "Base your findings only on verified information obtained via your tools. Never infer or imagine data that was not found. If a source cannot be accessed or no metadata is available, state that fact explicitly. Keep the exploration factual, concise, and high-level.\n",
    "\n",
    "# Instructions\n",
    "- Use your tools to discover and identify all accessible data sources as efficiently as possible.\n",
    "- Do not expand into schema-level details such as tables, columns, or keys.\n",
    "- Keep your report short, factual, and organized — avoid long explanations or speculation.\n",
    "- Do not ask the user for clarification; make reasonable assumptions and proceed.\n",
    "- Prioritize speed and completeness of coverage over depth.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52978e",
   "metadata": {},
   "source": [
    "### Input/Output\n",
    "We only have output here.\n",
    "\n",
    "\n",
    "#### Output\n",
    "\n",
    "This agent returns a `DataReport` containing a concise summary of discovered data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6467fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "class DataReport(BaseModel):\n",
    "    report: str = Field(\n",
    "        ..., \n",
    "        description=\"A concise single-paragraph report on the available data sources.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3435913b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: A concise single-paragraph report on the available data sources.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description(DataReport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c15cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_report = DataReport(\n",
    "    report=(\"[...] A nice concise description of the environment [...]\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a35218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataReport(report='[...] A nice concise description of the environment [...]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6643afe4",
   "metadata": {},
   "source": [
    "### Agent-as-Tool Wrap\n",
    "\n",
    "Here, we expose the agent **as a tool** (i.e., `discover_data_sources`) to be used by the Lead Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34333b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "async def discover_data_sources() -> DataReport:  # Returns a `DataReport`\n",
    "    \"\"\"Performs a one-time high-level discovery of all connected data sources \n",
    "    and returns a concise summary of available databases and their content domains.\"\"\"\n",
    "    \n",
    "    tools = genai_mcp.load_toolset(\"schema\")\n",
    "    \n",
    "    explorer_agent = Agent(\n",
    "        name=\"Data Expert\",\n",
    "        instructions=DATA_EXPERT_PROMPT,\n",
    "        model=config.experts_model,\n",
    "        tools=tools,\n",
    "        output_type=DataReport,\n",
    "    )\n",
    "\n",
    "    result = await Runner.run(explorer_agent, \"\", max_turns=config.data_expert_max_turns)\n",
    "\n",
    "    return result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8754fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "discover_data_sources_tool = function_tool(discover_data_sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a521f",
   "metadata": {},
   "source": [
    "## Expert Agent: Schema Expert\n",
    "\n",
    "The Schema Expert answers questions about database structure, relationships, and schema design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b20a6f",
   "metadata": {},
   "source": [
    "### Prompt/Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ad361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "SCHEMA_EXPERT_PROMPT = \"\"\"\n",
    "# Role and Objective\n",
    "You are a database expert specializing in answering schema-related questions for relational databases. You have tools that allow you to inspect and analyze schemas across multiple databases. Use these tools whenever they are beneficial to your analysis.\n",
    "\n",
    "# Core Behavioral Principle\n",
    "Never invent or infer schemas, tables, or columns that are not actually present in the inspected databases. If no relevant database or table exists, state that explicitly and stop. Do not describe hypothetical, example, or canonical schemas under any circumstance.\n",
    "\n",
    "# Instructions\n",
    "- Do not ask the user for clarification. For ambiguous questions, make reasonable assumptions and include them at the end of your answer—always present your answer first.\n",
    "- Identify which databases or data sources are relevant to the user's question.\n",
    "- Examine their schemas and explain how their structural elements (such as tables, columns, keys, and relationships) are connected.\n",
    "- Respond precisely to the user's intent, providing exactly the information requested—nothing more, nothing less.\n",
    "- Always state explicitly the names of the databases your answer pertains to; it is imperative that the user knows the specific databases referenced.\n",
    "- Avoid speculation, assumptions, or irrelevant details.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3849cf9",
   "metadata": {},
   "source": [
    "### Input/Output\n",
    "\n",
    "#### Input\n",
    "\n",
    "This agent expects a `SchemaQuery`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f99c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "class SchemaQuery(BaseModel):\n",
    "    context_hint: str = Field(\n",
    "        ..., \n",
    "        description=(\n",
    "            \"A high-level hint about which database or domain the tool should \"\n",
    "            \"focus on. This helps steer the tool toward the most relevant \"\n",
    "            \"data sources.\"\n",
    "        )\n",
    "    )\n",
    "    query: str = Field(\n",
    "        ..., \n",
    "        description=(\n",
    "            \"The natural language request or question about the schema of \"\n",
    "            \"the available relational databases.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def describe_for_agent(self) -> str:\n",
    "        return (\n",
    "            f\"### Schema Request or Question\\n{self.query}\\n\"\n",
    "            f\"### Relevant Context or Domain\\n{self.context_hint}\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3cdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_hint: A high-level hint about which database or domain the tool should focus on. This helps steer the tool toward the most relevant data sources.\n",
      "\n",
      "query: The natural language request or question about the schema of the available relational databases.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description(SchemaQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed050f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_query_example = SchemaQuery(\n",
    "    context_hint=\"[...] A high-level hint about which database or domain [...]\",\n",
    "    query=\"[...] The natural language request or question about the schema [...]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831608b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SchemaQuery(context_hint='[...] A high-level hint about which database or domain [...]', query='[...] The natural language request or question about the schema [...]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_query_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680630ff",
   "metadata": {},
   "source": [
    "#### Output\n",
    "\n",
    "The Schema Expert returns a `SchemaQueryAnswer` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42323b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "#| hide\n",
    "\n",
    "class SchemaQueryAnswer(BaseModel):\n",
    "    answer: str = Field(\n",
    "        ..., \n",
    "        description=(\n",
    "            \"The final synthesized answer to the user's schema-related question. \"\n",
    "            \"The response must explicitly state the names of all databases it pertains to.\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f88b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: The final synthesized answer to the user's schema-related question. The response must explicitly state the names of all databases it pertains to.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description(SchemaQueryAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9d33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_answer_example = SchemaQueryAnswer(\n",
    "    answer=\"[...] The final answer to the schema-related question [...]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab3479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SchemaQueryAnswer(answer='[...] The final answer to the schema-related question [...]')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema_answer_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9231241",
   "metadata": {},
   "source": [
    "### Agent-as-Tool Wrap\n",
    "\n",
    "Here, we expose the agent **as a tool** (i.e., `schema_query`) to be used by the Lead Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "async def schema_query(query: SchemaQuery  # The `SchemaQuery` instance containing the user's schema question\n",
    "                       ) -> SchemaQueryAnswer:  # The `SchemaQueryAnswer` instance containing the final answer\n",
    "    \"\"\"A tool that answers natural language questions about database schemas across \n",
    "    multiple potential relational database sources. It can describe tables, columns, \n",
    "    relationships, keys, and other structural details for the relevant database.\"\"\"\n",
    "\n",
    "    tools = genai_mcp.load_toolset(\"schema\")\n",
    "\n",
    "    agent = Agent(\n",
    "        name=\"Schema Expert\",\n",
    "        instructions=SCHEMA_EXPERT_PROMPT,\n",
    "        tools=tools,\n",
    "        model=config.experts_model,\n",
    "        output_type=SchemaQueryAnswer,\n",
    "    )\n",
    "\n",
    "    result = await Runner.run(agent, query.describe_for_agent(), max_turns=config.schema_expert_max_turns)\n",
    "\n",
    "    return result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b20e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "schema_query_tool = function_tool(schema_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb72fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebf254",
   "metadata": {},
   "source": [
    "## Expert Agent: SQL Expert\n",
    "\n",
    "he SQL Expert translates NL questions into SQL queries and returns the evidence (in SQL) for its answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7ee050",
   "metadata": {},
   "source": [
    "### Prompt/Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b76d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "SQL_EXPERT_PROMPT = \"\"\"\n",
    "# Role and Objective\n",
    "You are an SQL expert focused on transparency and reproducibility. Your goal is to answer the user's question as accurately and directly as possible, while *always displaying every final SQL query* that contributed evidence to your answer. Each part of your response must clearly show the concrete SQL query (or queries) that produced the corresponding result.  You have access to tools that allow you to execute SQL queries on various databases. Use these tools whenever they are beneficial to your analysis.\n",
    "\n",
    "# Evidence Traceability\n",
    "- For each analytical statement or conclusion you present, include the exact SQL query that generated the supporting data. \n",
    "- Only show SQL queries that were successfully executed and directly used to form your final answer. \n",
    "- Do not show intermediate or failed queries. \n",
    "- When multiple queries are used (for different sub-parts of the reasoning), display each query alongside the reasoning it supports, in clearly labeled sections.\n",
    "\n",
    "# Instructions\n",
    "- Do not ask the user for clarification. For ambiguous questions, make reasonable assumptions and include them at the end of your answer — always present your answer first.\n",
    "- Translate natural language questions into SQL queries, execute them, and communicate the results clearly in natural language.\n",
    "- Before executing any SQL query, verify that it is well-defined and addresses a single, specific information need.\n",
    "- For multi-step problems, plan the sequence of steps explicitly and execute them sequentially, integrating each intermediate result into the final coherent answer.\n",
    "- Ensure each SQL query matches the SQL dialect of the target database used by the query tool.\n",
    "\n",
    "# SQL Query Best Practices\n",
    "- Plan your approach before executing any query. \n",
    "- Prefer multiple simple, well-scoped queries over single complex ones by breaking problems into logical sub-steps.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3d269",
   "metadata": {},
   "source": [
    "### Input/Output\n",
    "\n",
    "#### Input\n",
    "\n",
    "This agent expects a `NLQuery` (we will later re-structure it manually in the `orchestration` module)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "\n",
    "class NLQuery(BaseModel):\n",
    "    query: str = Field(\n",
    "        ..., \n",
    "        description=\"The user's request or question expressed in natural language.\"\n",
    "    )\n",
    "    schema_info: str = Field(\n",
    "        ..., \n",
    "        description=(\n",
    "            \"The relevant database schema information, including the names of all \"\n",
    "            \"databases involved, as well as details on tables, relationships, and \"\n",
    "            \"foreign keys necessary for answering the query.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def describe_for_agent(self) -> str:\n",
    "        return (\n",
    "            f\"### NL Request or Question\\n{self.query}\\n\"\n",
    "            f\"### Relevant Schema Information for the Necessary Data\\n{self.schema_info}\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c505391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: The user's request or question expressed in natural language.\n",
      "\n",
      "schema_info: The relevant database schema information, including the names of all databases involved, as well as details on tables, relationships, and foreign keys necessary for answering the query.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description(NLQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_query_example = NLQuery(\n",
    "    query=\"[...] The user's request or question [...]\",\n",
    "    schema_info=\"[...] The relevant database schema information [...]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb6fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=\"[...] The user's request or question [...]\" schema_info='[...] The relevant database schema information [...]'\n"
     ]
    }
   ],
   "source": [
    "print(nl_query_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f572e4d",
   "metadata": {},
   "source": [
    "Since the LLMs expect NL inputs, we must structure multi-variable schemas accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820bab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### NL Request or Question\n",
      "[...] The user's request or question [...]\n",
      "### Relevant Schema Information for the Necessary Data\n",
      "[...] The relevant database schema information [...]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nl_query_example.describe_for_agent())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08935c5",
   "metadata": {},
   "source": [
    "#### Output\n",
    "\n",
    "The SQL Expert returns a `NLQueryAnswer`. This is a common structure we will use again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039af9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "#| hide\n",
    "\n",
    "class NLQueryAnswer(BaseModel):\n",
    "    answer: str = Field(\n",
    "        ..., \n",
    "        description=(\n",
    "            \"The final synthesized answer to the user's natural language query, expressed \"\n",
    "            \"clearly and completely in natural language.\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81f2df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer: The final synthesized answer to the user's natural language query, expressed clearly and completely in natural language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description(NLQueryAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31df87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nl_query_answer = NLQueryAnswer(\n",
    "    answer=\"[...] The final answer to a user's query (the 'user' can be an agent ofc) [...]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aadd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer=\"[...] The final answer to a user's query (the 'user' can be an agent ofc) [...]\"\n"
     ]
    }
   ],
   "source": [
    "print(nl_query_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b968655",
   "metadata": {},
   "source": [
    "### Agent-as-Tool Wrap\n",
    "\n",
    "Here, we expose the agent **as a tool** (i.e., `nl_query`) to be used by the Lead Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "async def nl_query(\n",
    "        query: NLQuery  # The `NLQuery` instance containing the user's question and schema info\n",
    "        ) -> NLQueryAnswer:  # The `NLQueryAnswer` instance containing the final answer and SQL evidence\n",
    "    \"\"\"Handles natural language questions by translating them into SQL, \n",
    "    executing the queries, and returning both the results and the concrete SQL \n",
    "    statements that produced them. Each part of the answer is accompanied by the \n",
    "    exact executed SQL query that served as its evidence.\"\"\"\n",
    "    \n",
    "    tools = genai_mcp.load_toolset(\"sql\")\n",
    "    \n",
    "    agent = Agent(\n",
    "        name=\"SQL Expert\",\n",
    "        instructions=SQL_EXPERT_PROMPT,\n",
    "        tools=tools,\n",
    "        model=config.experts_model,\n",
    "        output_type=NLQueryAnswer\n",
    "    )\n",
    "\n",
    "    result = await Runner.run(agent, query.describe_for_agent(), max_turns=config.sql_expert_max_turns)\n",
    "\n",
    "    return result.final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539a9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "nl_query_tool = function_tool(nl_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb254ad",
   "metadata": {},
   "source": [
    "## Lead Agent: Verifier\n",
    "\n",
    "The Verifier is the orchestrating agent that verifies claims by coordinating with other expert agents and grounding all conclusions in real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb5b6b",
   "metadata": {},
   "source": [
    "### Prompt/Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "VERIFIER_PROMPT = \"\"\"\n",
    "# Role and Objective\n",
    "You are a data expert and a verifier. Your goal is to verify every claim provided to you by grounding your reasoning in real, verifiable data sources. You have access to various tools that enable you to retrieve and analyze factual data—use them whenever they enhance your analysis. You must produce a clear and structured report that summarizes your findings and **includes the exact SQL queries** that generated the supporting evidence. Your query tools are specifically designed to return these executed SQL statements for inclusion in your report.\n",
    "\n",
    "# Data Grounding Principles\n",
    "- Always begin by exploring the available data sources to understand their structure and contents before interpreting the claim. This ensures your reasoning is firmly grounded in the real data environment.\n",
    "- Treat all accessible data sources as **reliable and authoritative**. You can fully trust that the data you access is accurate, complete within its scope, and suitable for verification.\n",
    "- Base your conclusions strictly on what the data supports. Avoid speculation or reasoning not grounded in evidence from the data.\n",
    "\n",
    "# Instructions\n",
    "- You should always base your conclusions on real data.\n",
    "- Do not ask the user for clarification. For ambiguous questions, first explore the available data environment to ground your interpretation in what the data represents. Then make reasonable assumptions about the claim's intent and clearly list them at the end of your report—after providing your answer.\n",
    "- Present the collected evidence directly in your report—including any executed SQL—ensuring that each conclusion is visibly grounded in data.\n",
    "- Verify each user claim by consulting available data sources.\n",
    "- Examine claims thoroughly and assess whether they are supported or contradicted by the evidence.\n",
    "- Use tools to obtain the information you need, delegating clear and well-scoped tasks to them when appropriate.\n",
    "- For multi-step questions, plan the reasoning explicitly and execute each step through a separate tool call. Each call should address one specific information need.\n",
    "- Remember: Tools are stateless. Recreate any necessary context between tool calls explicitly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85407ed",
   "metadata": {},
   "source": [
    "### Input/Output\n",
    "\n",
    "#### Input\n",
    "\n",
    "This agent expects a NL `UserQuery`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff494d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "#| hide\n",
    "\n",
    "class UserQuery(BaseModel):\n",
    "    query: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7dd923",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query_example = UserQuery(\n",
    "    query=\"[...] The user's request or question [...]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da4a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserQuery(query=\"[...] The user's request or question [...]\")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f41e2",
   "metadata": {},
   "source": [
    "#### Output\n",
    "\n",
    "The Verifier returns a `VerificationAnswer` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a902460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "#| hide\n",
    "\n",
    "class VerificationAnswer(BaseModel):\n",
    "    report: str = Field(\n",
    "        ...,\n",
    "        description=\"The full report describing which parts of the claims are true and which are not.\"\n",
    "    )\n",
    "    verdict: Literal[\"Verified\", \"Partly Verified\", \"Partly Inaccurate\", \"Inaccurate\"] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Your final verdict should be one of the following:\\n\"\n",
    "            \"- **Verified**: The overall claim is fully supported by the evidence, allowing for minor acceptable deviations (e.g., rounding, naming, or formatting differences).\\n\"\n",
    "            \"- **Partly Verified**: The overall claim is supported by the evidence, but some supporting details are incomplete, imprecise, or contain minor factual inaccuracies.\\n\"\n",
    "            \"- **Partly Inaccurate**: The overall claim contains a mixture of true and false elements, with errors substantial enough to undermine confidence in the conclusion.\\n\"\n",
    "            \"- **Inaccurate**: The overall claim is contradicted or unsupported by the evidence.\\n\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c9884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report: The full report describing which parts of the claims are true and which are not.\n",
      "\n",
      "verdict: Your final verdict should be one of the following:\n",
      "- **Verified**: The overall claim is fully supported by the evidence, allowing for minor acceptable deviations (e.g., rounding, naming, or formatting differences).\n",
      "- **Partly Verified**: The overall claim is supported by the evidence, but some supporting details are incomplete, imprecise, or contain minor factual inaccuracies.\n",
      "- **Partly Inaccurate**: The overall claim contains a mixture of true and false elements, with errors substantial enough to undermine confidence in the conclusion.\n",
      "- **Inaccurate**: The overall claim is contradicted or unsupported by the evidence.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "description(VerificationAnswer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f24b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_answer_example = VerificationAnswer(\n",
    "    report=\"[...] A detailed report on the verification of the claims with concrete SQL [...]\",\n",
    "    verdict=\"Verified\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83177d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VerificationAnswer(report='[...] A detailed report on the verification of the claims with concrete SQL [...]', verdict='Verified')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verification_answer_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ae4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c401d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b09a9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb8e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36696cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
